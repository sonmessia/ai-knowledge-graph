[llm]
model = "gemma3"
#model = "claude-3.5-sonnet-v2"
#model = "gpt4o"
#model = "llama3-2-90b-instruct-v1:0"
api_key = "sk-1234"
base_url = "http://localhost:11434/v1/chat/completions"
#base_url = "http://localhost:4000/v1/chat/completions"
max_tokens = 4096
temperature = 0.1  # Giảm để tăng tính nhất quán và độ chính xác

[chunking]
chunk_size = 150  # Tăng để giữ ngữ cảnh tốt hơn
overlap = 30      # Tăng để đảm bảo không mất thông tin quan trọng

[standardization]
enabled = true             
use_llm_for_entities = false  # Tắt để tránh LLM tự tạo entities

[inference]
enabled = false            # Tắt inference để tránh tạo relationships không chính xác
use_llm_for_inference = false  
apply_transitive = false   # Tắt để tránh suy luận có thể sai

[visualization]
edge_smooth = false
